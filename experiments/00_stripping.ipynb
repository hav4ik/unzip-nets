{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Manipulation\n",
    "\n",
    "Just trying ways to do graph manipulation in TensorFlow. [This][ge] seems promising, but the usage is not trivial.\n",
    "\n",
    "[ge]: https://www.tensorflow.org/api_guides/python/contrib.graph_editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "import keras.backend as K\n",
    "\n",
    "config = tf.ConfigProto(\n",
    "        device_count = {'GPU': 0},\n",
    "    )\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define a model\n",
    "\n",
    "Just a model that we're gonna perform surgery on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.layers as layers\n",
    "import keras.regularizers as reg\n",
    "\n",
    "with tf.variable_scope('model'):\n",
    "    inputs = layers.Input(shape=(32, 32, 3))\n",
    "    x = layers.Conv2D(32, (3, 3),\n",
    "                      kernel_initializer='glorot_uniform',\n",
    "                      kernel_regularizer=reg.l2(0.01))(inputs)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                      kernel_initializer='glorot_uniform',\n",
    "                      kernel_regularizer=reg.l2(0.01))(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation='relu',\n",
    "                     kernel_initializer='glorot_uniform',\n",
    "                     kernel_regularizer=reg.l2(0.01))(x)\n",
    "\n",
    "    ys = []\n",
    "    for i in range(3):\n",
    "        ys.append(layers.Dense(10, activation='softmax',\n",
    "            kernel_initializer='glorot_uniform')(x))\n",
    "\n",
    "model = keras.models.Model(inputs=[inputs], outputs=ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ts in model.losses:\n",
    "    tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stripping\n",
    "\n",
    "Here is our plan:\n",
    "- Assign weights to some layers\n",
    "- Save the graph state and terminate the session\n",
    "- Modify the graph with the Graph Editor.\n",
    "- create a new session and restore the graph state\n",
    "- Check the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we assign dope weights\n",
    "for var in tf.trainable_variables():\n",
    "    dope_w = np.ones(shape=var.get_shape()) * 1337\n",
    "    var.load(dope_w, sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.graph_editor as ge\n",
    "\n",
    "def get_tentacles(scope_name, within_ops=None):\n",
    "    if within_ops is None:\n",
    "        within_ops = []\n",
    "        for op in tf.get_default_graph().get_operations():\n",
    "            within_ops.append(op)\n",
    "\n",
    "    within_op_names = [op.name for op in within_ops]\n",
    "    ops = ge.get_name_scope_ops(within_ops, scope_name)\n",
    "    incoming, outcoming = {}, {}\n",
    "    \n",
    "    for op in ops:\n",
    "        src_ops = ge.get_generating_ops(op.inputs)\n",
    "        src_ops = [o for o in src_ops\n",
    "                   if o.name in within_op_names]\n",
    "        dst_ops = ge.get_consuming_ops(op.outputs)\n",
    "        dst_ops = [o for o in dst_ops\n",
    "                   if o.name in within_op_names]\n",
    "        \n",
    "        for o in src_ops:\n",
    "            if not o.name.startswith(scope_name):\n",
    "                if not op in incoming:\n",
    "                    incoming[op] = []\n",
    "                incoming[op].append(o)\n",
    "        for o in dst_ops:\n",
    "            if not o.name.startswith(scope_name):\n",
    "                if not op in outcoming:\n",
    "                    outcoming[op] = []\n",
    "                outcoming[op].append(o)\n",
    "                \n",
    "    return incoming, outcoming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.core.framework import variable_pb2\n",
    "\n",
    "\n",
    "def duplicate_layer(layer_name,\n",
    "                    layer_sgv,\n",
    "                    branch_name,\n",
    "                    add_to_collections=True):\n",
    "    \n",
    "    if layer_name[-1] == '/':\n",
    "        new_layer_name = layer_name[:-1] + branch_name + '/'\n",
    "    else:\n",
    "        new_layer_name = layer_name + branch_name\n",
    "\n",
    "    replacement_ts = {}\n",
    "    for op in layer_sgv.inputs:\n",
    "        replacement_ts[op] = op\n",
    "\n",
    "    duplicate_sgv, info = ge.copy_with_input_replacements(\n",
    "        layer_sgv,\n",
    "        replacement_ts=replacement_ts,\n",
    "        src_scope=layer_name,\n",
    "        dst_scope=new_layer_name)\n",
    "    \n",
    "    var_duplication = []\n",
    "    for v in tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES):\n",
    "        if layer_name not in v.name:\n",
    "            continue\n",
    "        vproto = v.to_proto()\n",
    "        new_vardef = variable_pb2.VariableDef()        \n",
    "        for field, val in vproto.ListFields():\n",
    "            if isinstance(val, str):\n",
    "                new_val = val.replace(layer_name, new_layer_name)\n",
    "            else:\n",
    "                new_val = val\n",
    "            setattr(new_vardef, field.name, new_val)\n",
    "        new_var = tf.Variable(variable_def=new_vardef)\n",
    "        tf.add_to_collection(tf.GraphKeys.GLOBAL_VARIABLES, new_var)\n",
    "        var_duplication.append((v, new_var))\n",
    "        \n",
    "        if add_to_collections:\n",
    "            for k in tf.get_default_graph().get_all_collection_keys():\n",
    "                collection = tf.get_collection(k)\n",
    "                if v in collection and new_var not in collection:\n",
    "                    tf.add_to_collection(k, new_var)            \n",
    "        \n",
    "    return info, var_duplication\n",
    "\n",
    "    \n",
    "def reroute_network(outcoming_dict, endpoints, dup_info):\n",
    "    branch_ops = ge.get_walks_intersection_ops(\n",
    "        forward_seed_ops=list(outcoming_dict),\n",
    "        backward_seed_ops=endpoints,\n",
    "        forward_inclusive=False,\n",
    "        backward_inclusive=True)\n",
    "    \n",
    "    outputs_to_swap = []\n",
    "    for op, outputs in outcoming_dict.items():\n",
    "        outputs_to_swap += [o for o in outputs if o in branch_ops]\n",
    "    \n",
    "    for node in outputs_to_swap:\n",
    "        orig_inputs = list(node.inputs)\n",
    "        new_inputs = []\n",
    "        for ts in orig_inputs:\n",
    "            new_op = dup_info.transformed(ts.op)\n",
    "            if new_op is not None:\n",
    "                new_inputs.extend(new_op.outputs)\n",
    "            else:\n",
    "                new_inputs.append(ts)\n",
    "        ge.reroute_inputs(new_inputs, node)\n",
    "    \n",
    "    \n",
    "def do_branching(layer_name, branching_scheme, network_ops=None):\n",
    "    incoming, outcoming = get_tentacles(layer_name, network_ops)\n",
    "    layer_sgv = ge.make_view_from_scope(layer_name, tf.get_default_graph())\n",
    "    \n",
    "    duplicates = []\n",
    "    for branch_name, network_outputs in branching_scheme.items():\n",
    "        if branch_name == '':\n",
    "            continue\n",
    "        info, dups = duplicate_layer(layer_name, layer_sgv, branch_name)\n",
    "        reroute_network(outcoming, network_outputs, info)\n",
    "        duplicates.extend(dups)\n",
    "    \n",
    "    return duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip(sess,\n",
    "          network_ops,\n",
    "          layer_name,\n",
    "          branching_scheme,\n",
    "          session_prep=None,\n",
    "          saver=None,\n",
    "          saver_scope='save'):\n",
    "    \n",
    "    if saver is None:\n",
    "        pre_surgery_saver = tf.train.Saver(name=saver_scope)\n",
    "    else:\n",
    "        pre_surgery_saver = saver\n",
    "    pre_surgery_saver.save(sess, '/tmp/pre_surgery')\n",
    "    sess.close()\n",
    "    \n",
    "    duplicate_var_pairs = do_branching(layer_name, branching_scheme, network_ops)\n",
    "    \n",
    "    if session_prep is None:\n",
    "        sess = tf.Session()\n",
    "    else:\n",
    "        sess = session_prep()\n",
    "    K.set_session(sess)\n",
    "    \n",
    "    pre_surgery_saver.restore(sess, '/tmp/pre_surgery')\n",
    "\n",
    "    for var, new_var in duplicate_var_pairs:\n",
    "        new_var.load(var.eval(sess), sess)\n",
    "    post_surgery_saver = tf.train.Saver()\n",
    "    post_surgery_saver.save(sess, '/tmp/post_surgery', write_meta_graph=False)\n",
    "    \n",
    "    non_saver_nodes = []\n",
    "    for node in tf.get_default_graph().as_graph_def().node:\n",
    "        if not node.name.startswith(saver_scope):\n",
    "            non_saver_nodes.append(node.name)\n",
    "    no_saver_graphdef = tf.graph_util.extract_sub_graph(\n",
    "        tf.get_default_graph().as_graph_def(), non_saver_nodes)\n",
    "    tf.train.export_meta_graph('/tmp/full_saver.meta', graph_def=no_saver_graphdef)\n",
    "    \n",
    "    sess.close()\n",
    "    K.clear_session()\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    if session_prep is None:\n",
    "        sess = tf.Session()\n",
    "    else:\n",
    "        sess = session_prep()\n",
    "    K.set_session(sess)\n",
    "    \n",
    "    full_saver = tf.train.import_meta_graph('/tmp/full_saver.meta')\n",
    "    full_saver.restore(sess, '/tmp/post_surgery')\n",
    "    \n",
    "    return sess, full_saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_ops = ge.get_backward_walk_ops(model.outputs)\n",
    "layer_name = 'model/dense_1/'\n",
    "branching_scheme = {\n",
    "    '': model.outputs[0],\n",
    "    'a': model.outputs[1:]\n",
    "}\n",
    "\n",
    "writer = tf.summary.FileWriter('vis_before', tf.get_default_graph())\n",
    "writer.close()\n",
    "\n",
    "sess, saver = unzip(sess, network_ops, layer_name, branching_scheme)\n",
    "\n",
    "writer = tf.summary.FileWriter('vis_after', tf.get_default_graph())\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
